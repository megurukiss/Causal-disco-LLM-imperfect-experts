{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.5.1 available.\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from causaldag import DAG\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from algo.greedy_search import greedy_search_mec_size, greedy_search_confidence, greedy_search_bic\n",
    "\n",
    "from models.noisy_expert import NoisyExpert\n",
    "from models.oracles import EpsilonOracle\n",
    "\n",
    "from utils.data_generation import generate_dataset\n",
    "from utils.dag_utils import get_undirected_edges, is_dag_in_mec, get_mec, get_undirected_edges_pdag\n",
    "from utils.metrics import get_mec_shd\n",
    "from utils.language_models import get_lms_probs, temperature_scaling\n",
    "from utils.CI_utils import load_data_from_file, save_data_to_file, data2pdag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=\"greedy_conf\"\n",
    "prior=\"mec\"\n",
    "dataset=\"asia\"\n",
    "tabular=False\n",
    "probability=\"posterior\"\n",
    "preprocess=False\n",
    "calibrate=False\n",
    "epsilon=0.05\n",
    "tolerance=0.1\n",
    "seed=953100\n",
    "verbose=False\n",
    "\n",
    "\n",
    "def blindly_follow_expert(observed_arcs, model, cpdag, *args, **kwargs):\n",
    "    return [list(observed_arcs) + list(cpdag.arcs)], observed_arcs, model(observed_arcs, observed_arcs)\n",
    "\n",
    "\n",
    "match algo:\n",
    "    case \"greedy_mec\":\n",
    "        algo = greedy_search_mec_size\n",
    "    case \"greedy_conf\":\n",
    "        algo = greedy_search_confidence\n",
    "    case \"greedy_bic\":\n",
    "        algo = greedy_search_bic\n",
    "        tolerance = 1.\n",
    "\n",
    "    case \"global_scoring\":\n",
    "        from algo.global_scoring import global_scoring\n",
    "        algo = global_scoring\n",
    "        tolerance = 1.\n",
    "\n",
    "    case \"PC\":\n",
    "        algo = lambda a, b, cpdag, c, tol: (get_mec(cpdag), dict(), 1.)\n",
    "        tolerance = 0.\n",
    "    case \"naive\":\n",
    "        algo = blindly_follow_expert\n",
    "        tolerance = 1.\n",
    "\n",
    "match prior:\n",
    "    case \"mec\":\n",
    "        from models.priors import MECPrior\n",
    "        prior_type = MECPrior\n",
    "    \n",
    "    case \"independent\":\n",
    "        from models.priors import IndependentPrior\n",
    "        prior_type = IndependentPrior\n",
    "\n",
    "if not os.path.exists(\"_raw_bayesian_nets\"):\n",
    "    from utils.download_datasets import download_datasets\n",
    "    download_datasets()\n",
    "\n",
    "true_G, data = generate_dataset('_raw_bayesian_nets/' + dataset + '.bif')\n",
    "\n",
    "if preprocess:\n",
    "    # use pc and ges to generate the cpdag\n",
    "    # try load data\n",
    "    try:\n",
    "        data = load_data_from_file('./' + dataset+'_data' + '.pkl')\n",
    "    except:\n",
    "        # save data\n",
    "        save_data_to_file(data, './' + dataset+'_data' + '.pkl')\n",
    "    \n",
    "    cpdag = data2pdag(data)\n",
    "\n",
    "else:\n",
    "    cpdag = DAG.from_nx(true_G).cpdag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_edges = get_undirected_edges(true_G, verbose=verbose)\n",
    "llm_engine=\"text-davinci-002\"\n",
    "if tabular:\n",
    "    oracle = EpsilonOracle(undirected_edges, epsilon=epsilon)\n",
    "    observations = oracle.decide_all()\n",
    "    likelihoods = oracle.likelihoods\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        codebook = pd.read_csv('codebooks/' + dataset + '.csv')\n",
    "    except:\n",
    "        print('cannot load the codebook')\n",
    "        codebook = None\n",
    "\n",
    "    if calibrate:\n",
    "        tmp_scale, eps = temperature_scaling(cpdag.arcs, codebook, engine=llm_engine)\n",
    "        print(\"LLM has %.3f error rate\" % eps)\n",
    "    else:\n",
    "        tmp_scale = 1.\n",
    "\n",
    "    likelihoods, observations = get_lms_probs(undirected_edges, codebook, tmp_scale, engine=llm_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('asia', 'tub'), ('smoke', 'bronc'), ('smoke', 'lung')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Orientations: {('smoke', 'lung'), ('smoke', 'bronc'), ('asia', 'tub')}\n",
      "\n",
      "Orientations given by the expert: [('smoke', 'lung'), ('smoke', 'bronc'), ('asia', 'tub')]\n",
      "{('smoke', 'lung'): 0.9972375690555538, ('lung', 'smoke'): 0.002762430944446141, ('smoke', 'bronc'): 0.9982206405683903, ('bronc', 'smoke'): 0.0017793594316096988, ('asia', 'tub'): 0.8571428571360543, ('tub', 'asia'): 0.14285714286394557}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrue Orientations:\", undirected_edges)\n",
    "print(\"\\nOrientations given by the expert:\", observations)\n",
    "print(likelihoods)\n",
    "prior = prior_type(cpdag)\n",
    "model = NoisyExpert(prior, likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "match probability:\n",
    "    case \"posterior\":\n",
    "        prob_method = model.posterior\n",
    "    \n",
    "    case \"likelihood\":\n",
    "        prob_method = model.likelihood\n",
    "\n",
    "    case \"prior\":\n",
    "        prob_method = lambda _, edges: prior(edges)\n",
    "\n",
    "new_mec, decisions, p_correct = algo(observations, prob_method, cpdag, likelihoods, tol=tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final wrong orientations: [('tub', 'asia')]\n",
      "\n",
      "Confidence true DAG is in final MEC: 0.994\n",
      "Final MEC's SHD:  1.0\n",
      "MEC size:  2\n",
      "true-still-in-MEC:  1.0\n"
     ]
    }
   ],
   "source": [
    "shd, learned_adj = get_mec_shd(true_G, new_mec)\n",
    "    \n",
    "learned_G = nx.from_numpy_array(learned_adj, create_using=nx.DiGraph)\n",
    "learned_G = nx.relabel_nodes(learned_G, {i: n for i, n in zip(learned_G.nodes, true_G.nodes)})\n",
    "\n",
    "diff = nx.difference(learned_G, true_G)\n",
    "print(\"\\nFinal wrong orientations:\", diff.edges)\n",
    "\n",
    "print('\\nConfidence true DAG is in final MEC: %.3f' % p_correct)\n",
    "print(\"Final MEC's SHD: \", shd)\n",
    "print('MEC size: ', len(new_mec))\n",
    "print('true-still-in-MEC: ', is_dag_in_mec(true_G, new_mec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({('bronc', 'dysp'), ('lung', 'either'), ('either', 'xray'), ('either', 'dysp'), ('tub', 'either')}, {('bronc', 'smoke'), ('asia', 'tub'), ('smoke', 'lung')})\n",
      "({('bronc', 'dysp'), ('lung', 'either'), ('smoke', 'bronc'), ('either', 'xray'), ('either', 'dysp'), ('smoke', 'lung'), ('tub', 'either')}, {('asia', 'tub')})\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "def mec_to_graph(mec_list):\n",
    "    directed_set = set()\n",
    "    undirected_set = set()\n",
    "    for mec in mec_list:\n",
    "        for edge in mec:\n",
    "            # if (edge[0], edge[1]) in directed_set, do nothing; if (edge[1], edge[0]) in directed_set, remove it, add to undirected_set\n",
    "            if (edge[0], edge[1]) in directed_set or ((edge[0], edge[1]) in undirected_set or (edge[1], edge[0]) in undirected_set):\n",
    "                continue\n",
    "            elif (edge[1], edge[0]) in directed_set:\n",
    "                directed_set.remove((edge[1], edge[0]))\n",
    "                undirected_set.add((edge[0], edge[1]))\n",
    "            else:\n",
    "                directed_set.add(edge)  \n",
    "    return directed_set, undirected_set\n",
    "\n",
    "print(mec_to_graph(get_mec(cpdag)))\n",
    "print(mec_to_graph(new_mec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('bronc', 'dysp'),\n",
       " ('either', 'dysp'),\n",
       " ('either', 'xray'),\n",
       " ('lung', 'either'),\n",
       " ('tub', 'either')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdag.arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smoke', 'lung'), ('smoke', 'lung'), ('smoke', 'bronc'), ('smoke', 'bronc')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
